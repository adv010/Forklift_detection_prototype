{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/utils/multiclass.py:13: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.\n",
      "  from scipy.sparse.base import spmatrix\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "from IPython.display import Image  # for displaying images\n",
    "import os \n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "\n",
    "# random.seed(108)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../yolov5\n",
    "PATH = \"./Results/yolovs_100_0.6thresh/weights/best.pt\"\n",
    "device = torch.device(\"cuda\")\n",
    "model = torch.load(PATH)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "stream = cv2.VideoCapture(0) # 0 means read from local camera.\n",
    "def score_frame(frame, model):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    frame = [torch.tensor(frame)]\n",
    "    results = self.model(frame)\n",
    "    labels = results.xyxyn[0][:, -1].numpy()\n",
    "    cord = results.xyxyn[0][:, :-1].numpy()\n",
    "    return labels, cord\n",
    "\n",
    "def plot_boxes(self, results, frame):\n",
    "    labels, cord = results\n",
    "    n = len(labels)\n",
    "    x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "    for i in range(n):\n",
    "        row = cord[i]\n",
    "        # If score is less than 0.2 we avoid making a prediction.\n",
    "        if row[4] < 0.2: \n",
    "            continue\n",
    "        x1 = int(row[0]*x_shape)\n",
    "        y1 = int(row[1]*y_shape)\n",
    "        x2 = int(row[2]*x_shape)\n",
    "        y2 = int(row[3]*y_shape)\n",
    "        bgr = (0, 255, 0) # color of the box\n",
    "        classes = self.model.names # Get the name of label index\n",
    "        label_font = cv2.FONT_HERSHEY_SIMPLEX #Font for the label.\n",
    "        cv2.rectangle(frame, \\\n",
    "                      (x1, y1), (x2, y2), \\\n",
    "                       bgr, 2) #Plot the boxes\n",
    "        cv2.putText(frame,\\\n",
    "                    classes[labels[i]], \\\n",
    "                    (x1, y1), \\\n",
    "                    label_font, 0.9, bgr, 2) #Put a label over box.\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Function below oracestrates the entire operation and performs the real-time parsing for video stream.\n",
    "\"\"\"\n",
    "def __call__(self):\n",
    "    player = self.get_video_stream() #Get your video stream.\n",
    "    assert player.isOpened() # Make sure that their is a stream. \n",
    "    #Below code creates a new video writer object to write our\n",
    "    #output stream.\n",
    "    x_shape = int(player.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    y_shape = int(player.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    four_cc = cv2.VideoWriter_fourcc(*\"MJPG\") #Using MJPEG codex\n",
    "    out = cv2.VideoWriter(out_file, four_cc, 20, \\\n",
    "                          (x_shape, y_shape)) \n",
    "    ret, frame = player.read() # Read the first frame.\n",
    "    while rect: # Run until stream is out of frames\n",
    "        start_time = time() # We would like to measure the FPS.\n",
    "        results = self.score_frame(frame) # Score the Frame\n",
    "        frame = self.plot_boxes(results, frame) # Plot the boxes.\n",
    "        end_time = time()\n",
    "        fps = 1/np.round(end_time - start_time, 3) #Measure the FPS.\n",
    "        print(f\"Frames Per Second : {fps}\")\n",
    "        out.write(frame) # Write the frame onto the output.\n",
    "        ret, frame = player.read() # Read next frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=forkliftload.yaml, hyp=hyp.scratch.yaml, epochs=50, batch_size=4, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=2, project=runs/train, name=forkliftload_det, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "Parse error at \"'python=='\": Expected stringEnd\n",
      "YOLOv5 ðŸš€ 2022-7-28 Python-3.8.13 torch-1.12.0+cu102 CUDA:0 (NVIDIA GeForce MX330, 2003MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.5, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=10.0, translate=0.1, scale=0.9, shear=5.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.5\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "2022-07-29 10:19:51.867715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-07-29 10:19:51.867866: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:00<00:00, 25.4MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 270 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "Scaled weight_decay = 0.0005\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/utils/multiclass.py:13: DeprecationWarning: Please use `spmatrix` from the `scipy.sparse` namespace, the `scipy.sparse.base` namespace is deprecated.\n",
      "  from scipy.sparse.base import spmatrix\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:1074: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:1306: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=1, eps=np.finfo(np.float).eps,\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/least_angle.py:1442: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/utils/optimize.py:18: DeprecationWarning: Please use `line_search_wolfe2` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/utils/optimize.py:18: DeprecationWarning: Please use `line_search_wolfe1` from the `scipy.optimize` namespace, the `scipy.optimize.linesearch` namespace is deprecated.\n",
      "  from scipy.optimize.linesearch import line_search_wolfe2, line_search_wolfe1\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/randomized_l1.py:318: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/linear_model/randomized_l1.py:575: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=1,\n",
      "/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/sklearn/decomposition/online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/adv8/Documents/HiWi/I4SE/forkliftload/yolov5/../forkliftl\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/adv8/Documents/HiWi/I4SE/forkliftload/yolov5/../forkliftload_data/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/adv8/Documents/HiWi/I4SE/forkliftload/yolov5/../forkliftloa\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/adv8/Documents/HiWi/I4SE/forkliftload/yolov5/../forkliftload_data/labels/val.cache\n",
      "Plotting labels to runs/train/forkliftload_det/labels.jpg... \n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.40 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/forkliftload_det\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
      "      0/49    0.883G   0.09873   0.03652   0.02488        14       640:  80%|â–ˆâ–ˆâ–ˆ^C\n",
      "      0/49    0.883G   0.09873   0.03652   0.02488        14       640:  80%|â–ˆâ–ˆâ–ˆ\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 642, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 537, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 301, in train\n",
      "    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
      "  File \"/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/tqdm/std.py\", line 1195, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/adv8/Documents/HiWi/I4SE/forkliftload/yolov5/utils/dataloaders.py\", line 167, in __iter__\n",
      "    yield next(self.iterator)\n",
      "  File \"/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 652, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1330, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1286, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1134, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/home/adv8/anaconda3/envs/py38/lib/python3.8/queue.py\", line 179, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/home/adv8/anaconda3/envs/py38/lib/python3.8/threading.py\", line 306, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Uses oretrained weights of yolov5.pt from https://github.com/ultralytics/yolov5\n",
    "\n",
    "!python train.py --img 640 --cfg yolov5s.yaml --hyp hyp.scratch.yaml --batch 4 --epochs 50 --data forkliftload.yaml --weights yolov5s.pt --workers 2 --name forkliftload_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./Results/yolovs_100_0.6thresh/weights/best.pt'], source=../forkliftload_data/images/test/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "Parse error at \"'python=='\": Expected stringEnd\n",
      "YOLOv5 ðŸš€ 2022-7-28 Python-3.8.13 torch-1.12.0+cu102 CUDA:0 (NVIDIA GeForce MX330, 2003MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/7 /home/adv8/Documents/HiWi/I4SE/forkliftload/forkliftload_data/images/test/20220715_083943760_iOS.jpg: 640x480 1 Carton boxes, Done. (0.024s)\n",
      "image 2/7 /home/adv8/Documents/HiWi/I4SE/forkliftload/forkliftload_data/images/test/20220715_103627159_iOS.jpg: 640x480 2 Carton boxess, Done. (0.024s)\n",
      "image 3/7 /home/adv8/Documents/HiWi/I4SE/forkliftload/forkliftload_data/images/test/20220715_105833486_iOS.jpg: 640x480 1 Carton boxes, Done. (0.024s)\n",
      "image 4/7 /home/adv8/Documents/HiWi/I4SE/forkliftload/forkliftload_data/images/test/20220715_110337624_iOS.jpg: 640x480 2 Carton boxess, Done. (0.024s)\n",
      "image 5/7 /home/adv8/Documents/HiWi/I4SE/forkliftload/forkliftload_data/images/test/20220715_110634276_iOS.jpg: 640x480 2 Carton boxess, Done. (0.024s)\n",
      "image 6/7 /home/adv8/Documents/HiWi/I4SE/forkliftload/forkliftload_data/images/test/20220715_110757101_iOS.jpg: 640x480 2 Carton boxess, Done. (0.024s)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"detect.py\", line 257, in <module>\n",
      "    main(opt)\n",
      "  File \"detect.py\", line 252, in main\n",
      "    run(**vars(opt))\n",
      "  File \"/home/adv8/anaconda3/envs/py38/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"detect.py\", line 111, in run\n",
      "    for path, im, im0s, vid_cap, s in dataset:\n",
      "  File \"/home/adv8/Documents/HiWi/I4SE/forkliftload/yolov5/utils/dataloaders.py\", line 246, in __next__\n",
      "    img0 = cv2.imread(path)  # BGR\n",
      "  File \"/home/adv8/Documents/HiWi/I4SE/forkliftload/yolov5/utils/general.py\", line 1014, in imread\n",
      "    return cv2.imdecode(np.fromfile(path, np.uint8), flags)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python detect.py --weights ./Results/yolovs_100_0.6thresh/weights/best.pt --source ../forkliftload_data/images/test/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b860e4f9478aaf4a84c36d5ac6aeca6214a9e0903092d6742dae95c3d2c786cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
